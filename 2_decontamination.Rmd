---
title: "decontamination of pcr replicates and ASVs for rockfish dloop mock communities and bottom trawl samples"
author: "Kimberly Ledger"
date: "2024-11-08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

libraries
```{r}
library(tidyverse)
rename <- dplyr::rename
library(reshape2)
```

load sample metadata
```{r}
metadata <- read.csv("/home/kimberly.ledger/rockfish_mb/data/metadata_tissue_mock_bt22.csv") %>%
  rename(Sample_ID = sample_ID) %>%
  mutate(sample_type = ifelse(Sample_ID == "PC", "pcr_blank", sample_type),
         sample_type = ifelse(Sample_ID == "NC", "positive", sample_type))    ### ids for pc and nc were flip-flopped  
```

check sequence table outputs
```{r}
asv_table <- readRDS("/home/kimberly.ledger/rockfish_mb/data/dadasnake_output/filtered.seqTab.RDS") %>%
  select(!Row.names)

#transpose 
asv_table <- data.frame(t(asv_table))

#set column names to be ASV# 
colnames(asv_table) <- asv_table["ASV",]

#remove row that has ASV#
asv_table <- asv_table[!rownames(asv_table) %in% c('ASV'), ]

#make sure reads are numbers
# Convert all character columns to numeric
for (col in names(asv_table)) {
  asv_table[[col]] <- as.numeric(asv_table[[col]])
}

#make make sample ID a column 
asv_table$Sample_ID <- rownames(asv_table)

asv_table <- asv_table %>%
  select(Sample_ID, everything()) %>%
  mutate(across(everything(), ~ gsub("-", "_", .))) %>%
  mutate(Sample_ID = ifelse(Sample_ID == "NC22_1_A", "NC22-1_A", Sample_ID)) %>%
  mutate(Sample_ID = ifelse(Sample_ID == "NC22_2_A", "NC22-2_A", Sample_ID))
```

add column to the ASV table that labels the sample type
```{r}
asv_table_with_sample_type <- metadata %>%
  dplyr::select(Sample_ID, sample_type) %>%
  left_join(asv_table, by = "Sample_ID")

# make a variable for the first and last ASV column in the table
asv_first <- which(startsWith(names(asv_table_with_sample_type), "ASV"))[1]
asv_last <- ncol(asv_table_with_sample_type)
```

pivot table longer 
```{r}
asv_table_long <- asv_table_with_sample_type %>%
  pivot_longer(cols = c(asv_first:asv_last), names_to = "ASV", values_to = "reads") %>%
  mutate(reads = as.numeric(reads)) %>%
  mutate(reads = ifelse(is.na(reads), 0, reads))
```

# account for likely contaminants 

step 1: remove ASVs that don't get a rockfish taxonomic assignment 
step 2: remove any ASVs that don't show up in field samples (there were none)
step 3: remove low read depth samples based on ASV accumulation curve  

## Step 1. Remove ASVs that don't get a taxonomic assignment  

```{r}
taxonomy <- read.csv("/home/kimberly.ledger/rockfish_mb/data/taxonomy_custom534_20250117.csv") %>% 
  select(!X) %>%
  rename(ASV = qseqid)

asv_table_filter1 <- asv_table_long %>%
  filter(ASV %in% taxonomy$ASV)

length(unique(taxonomy$ASV))
```

## Step 2. Remove ASVs that do not occur in samples, tissues, or mock communities
i.e. just in controls or MIA

```{r}
reads_per_type_ASV <- asv_table_filter1 %>%
  group_by(ASV, sample_type) %>%
  summarize(TotalReadsPerASV = sum(reads, na.rm = TRUE)) %>%
  arrange(ASV)
```

what ASVs have no reads in samples or mock communities, but reads in the controls? 
```{r}
not_in_samples <- reads_per_type_ASV %>%
  pivot_wider(names_from = "sample_type", values_from = c("TotalReadsPerASV")) %>%
    filter(sample < 1 & mock < 1 & tissue < 1 & field_blank < 1)
not_in_samples
```

there are none. 

## Step 3. Remove low read depth samples based on ASV accumulation curve

run separately for tissue samples 
```{r}
library(vegan)

asv_table_wide_tissue <- asv_table_filter1 %>%
  filter(sample_type == "tissue") %>%
  filter(!Sample_ID %in% c("34137", "34138", "34139", "34140")) %>%  ## remove tissues not included in study 
  select(!sample_type) %>%
  mutate(reads = as.integer(reads)) %>%
  pivot_wider(names_from = ASV, values_from = reads)

sample_IDs <- asv_table_wide_tissue$Sample_ID

asv_table_wide_tissue <- asv_table_wide_tissue %>%
  ungroup() %>%
  select(-Sample_ID)

## plots the figure
rarecurve(asv_table_wide_tissue, step = 20, col = "blue", label = FALSE, 
          main = "Sequencing Effort Curves",
          xlab = "Sequencing Depth", ylab = "Number of ASVs Identified",
          xlim = c(0,400))
```

run separately for eDNA samples 
```{r}
asv_table_wide_sample <- asv_table_filter1 %>%
  filter(sample_type == "sample") %>%
  select(!sample_type) %>%
  mutate(reads = as.integer(reads)) %>%
  pivot_wider(names_from = ASV, values_from = reads)

sample_IDs <- asv_table_wide_sample$Sample_ID

asv_table_wide_sample <- asv_table_wide_sample %>%
  ungroup() %>%
  select(-Sample_ID)

## plots the figure
rarecurve(asv_table_wide_sample, step = 20, col = "blue", label = FALSE, 
          main = "Sequencing Effort Curves",
          xlab = "Sequencing Depth", ylab = "Number of ASVs Identified",
          xlim = c(0,1000))
```


summarize in a table how many pcr replicates meet certain read count thresholds 
```{r}
read_summary <- asv_table_filter1 %>%
  filter(!Sample_ID %in% c("34137", "34138", "34139", "34140")) %>%  ## remove tissues not included in study 
  group_by(Sample_ID, sample_type) %>%
  summarize(tot_reads = sum(reads)) %>%
  arrange(desc(tot_reads)) %>%
  group_by(sample_type) %>%
  summarize(atleast1 = sum(tot_reads >= 1),
            atleast100 = sum(tot_reads >= 100),
            atleast200 = sum(tot_reads >= 200),
            atleast500 = sum(tot_reads >= 500),
            atleast1k = sum(tot_reads >= 1000))
```

based on taxa accumulation curve and summary table, we will remove any pcr replicate with fewer than 200 reads from downstream analyses for JUST the EDNA SAMPLES

```{r}
reps_below <- asv_table_filter1 %>%
  group_by(Sample_ID) %>%
  summarise(tot_reads = sum(reads)) %>%
  filter(tot_reads < 200)
```

```{r}
asv_table_filter2 <- asv_table_filter1 %>%
  filter(!Sample_ID %in% reps_below$Sample_ID)
```

```{r}
sum(asv_table_filter1$reads)
sum(asv_table_filter2$reads)
sum(asv_table_long$reads)
```

```{r}
2290034/2295159
```
```{r}
asv_table_with_sample_type %>%
  group_by(sample_type) %>%
  summarize(count = n())
```

```{r}
#write.csv(asv_table_filter2, "/home/kimberly.ledger/rockfish_mb/data/decontaminated_asv_table.csv")
#write.csv(asv_table_filter1, "/home/kimberly.ledger/rockfish_mb/data/decontaminated_asv_table_noreadcountfilter.csv")
```