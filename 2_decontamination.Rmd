---
title: "decontamination of pcr replicates and ASVs for rockfish dloop mock communities and bottom trawl samples"
author: "Kimberly Ledger"
date: "2024-11-08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

libraries
```{r}
library(tidyverse)
rename <- dplyr::rename
library(reshape2)
```

load sample metadata
```{r}
metadata <- read.csv("/home/kimberly.ledger/rockfish_mb/data/metadata_tissue_mock_bt22.csv") %>%
  rename(Sample_ID = sample_ID) %>%
  mutate(sample_type = ifelse(Sample_ID == "PC", "pcr_blank", sample_type),
         sample_type = ifelse(Sample_ID == "NC", "positive", sample_type))    ### if flip-flopped these IDs 
```

check sequence table outputs
```{r}
asv_table <- readRDS("/home/kimberly.ledger/rockfish_mb/data/dadasnake_output/filtered.seqTab.RDS") %>%
  select(!Row.names)

#transpose 
asv_table <- data.frame(t(asv_table))

#set column names to be ASV# 
colnames(asv_table) <- asv_table["ASV",]

#remove row that has ASV#
asv_table <- asv_table[!rownames(asv_table) %in% c('ASV'), ]

#make sure reads are numbers
# Convert all character columns to numeric
for (col in names(asv_table)) {
  asv_table[[col]] <- as.numeric(asv_table[[col]])
}

#make make sample ID a column 
asv_table$Sample_ID <- rownames(asv_table)

asv_table <- asv_table %>%
  select(Sample_ID, everything()) %>%
  mutate(across(everything(), ~ gsub("-", "_", .))) %>%
  mutate(Sample_ID = ifelse(Sample_ID == "NC22_1_A", "NC22-1_A", Sample_ID)) %>%
  mutate(Sample_ID = ifelse(Sample_ID == "NC22_2_A", "NC22-2_A", Sample_ID))
```

add column to the ASV table that labels the sample type
```{r}
asv_table_with_sample_type <- metadata %>%
  dplyr::select(Sample_ID, sample_type) %>%
  left_join(asv_table, by = "Sample_ID")

# make a variable for the first and last ASV column in the table
asv_first <- which(startsWith(names(asv_table_with_sample_type), "ASV"))[1]
asv_last <- ncol(asv_table_with_sample_type)
```


# account for likely contaminants 

step 1: tag-jumping: subtract the proportion of reads that jumped into the positive control samples from each environmental sample 
step 2: remove ASVs that don't get a rockfish taxonomic assignment 
step 3: remove any ASVs that don't show up in field samples 
step 4: remove low read depth samples based on ASV accumulation curve  
step 5: check dissimilarity across PCR replicates and remove any replicates with high dissimilarity 


## Step 1. Account for tag-jumping by using the positive controls 

subtract the proportion of reads that jumped into the positive control samples from each environmental sample 

plot the positive controls
```{r}
asv_table_with_sample_type %>%
  pivot_longer(cols = c(asv_first:asv_last), names_to = "ASV", values_to = "reads") %>%
  mutate(reads = as.numeric(reads)) %>%
  mutate(reads = ifelse(is.na(reads), 0, reads)) %>%
  filter(sample_type %in% c("positive")) %>%
  filter(reads > 0) %>%
  ggplot(aes(x=Sample_ID, y=reads, fill=ASV)) +
  geom_bar(stat = "identity") + 
  theme_bw() +
  labs(
    y = "number of sequencing reads",
    x = "sample ID",
    title = "ASV reads - positive controls") + 
  theme(
    axis.text.x = element_text(angle = 90, hjust = 0.95),
    legend.text = element_text(size = 8),
    legend.key.size = unit(0.3, "cm"),
    #legend.position = "none",
    legend.title = element_blank()
  )
```

identify the maximum proportion of reads for each ASV found in the positive controls
note: can only base this off PC22_A since the PC in the other plate was pop and that's a target species 
```{r}
prop_asvs_in_positives <- asv_table_with_sample_type %>%
  filter(Sample_ID == "PC22_A") %>%
  pivot_longer(cols = c(asv_first:asv_last), names_to = "ASV", values_to = "reads") %>%
  mutate(reads = as.numeric(reads)) %>%
  group_by(Sample_ID) %>%
  mutate(TotalReadsPerSample = sum(reads)) %>%
  mutate(Prop = reads/TotalReadsPerSample) %>%
  group_by(ASV) %>%
  summarise(max_prop = max(Prop)) %>%
  arrange(desc(max_prop))
```

i'm not loving that there is only one pc sample to base this on. not going to subtract reads here. 

subtract the max proportion of tag-jumped reads for each ASV from samples
```{r}
asv_table_long <- asv_table_with_sample_type %>%
  pivot_longer(cols = c(asv_first:asv_last), names_to = "ASV", values_to = "reads") %>%
  mutate(reads = as.numeric(reads)) %>%
  mutate(reads = ifelse(is.na(reads), 0, reads))
```


## Step 2. Remove ASVs that don't get a taxonomic assignment  

```{r}
taxonomy <- read.csv("/home/kimberly.ledger/rockfish_mb/data/taxonomy_custom534_20250117.csv") %>% 
  select(!X) %>%
  rename(ASV = qseqid)

asv_table_filter1 <- asv_table_long %>%
  filter(ASV %in% taxonomy$ASV)

length(unique(taxonomy$ASV))
```


## Step 3. Remove ASVs that do not occur in samples, tissues, or mock communities
i.e. just in controls or MIA

```{r}
reads_per_type_ASV <- asv_table_filter1 %>%
  group_by(ASV, sample_type) %>%
  summarize(TotalReadsPerASV = sum(reads, na.rm = TRUE)) %>%
  arrange(ASV)
```

what ASVs have no reads in samples or mock communities, but reads in the controls? 
```{r}
not_in_samples <- reads_per_type_ASV %>%
  pivot_wider(names_from = "sample_type", values_from = c("TotalReadsPerASV")) %>%
    filter(sample < 1 & mock < 1 & tissue < 1 & field_blank < 1)
not_in_samples
```

there are none. 

## Step 4. Remove low read depth samples based on ASV accumulation curve

run separately for tissue and eDNA samples 
```{r}
library(vegan)

asv_table_wide_tissue <- asv_table_filter1 %>%
  filter(sample_type == "tissue") %>%
  filter(!Sample_ID %in% c("34137", "34138", "34139", "34140")) %>%  ## remove wierd yelloweye tissues
  select(!sample_type) %>%
  mutate(reads = as.integer(reads)) %>%
  pivot_wider(names_from = ASV, values_from = reads)

sample_IDs <- asv_table_wide_tissue$Sample_ID

asv_table_wide_tissue <- asv_table_wide_tissue %>%
  ungroup() %>%
  select(-Sample_ID)

## plots the figure
rarecurve(asv_table_wide_tissue, step = 20, col = "blue", label = FALSE, 
          main = "Sequencing Effort Curves",
          xlab = "Sequencing Depth", ylab = "Number of ASVs Identified",
          xlim = c(0,400))
```


```{r}
asv_table_wide_sample <- asv_table_filter1 %>%
  filter(sample_type == "sample") %>%
  select(!sample_type) %>%
  mutate(reads = as.integer(reads)) %>%
  pivot_wider(names_from = ASV, values_from = reads)

sample_IDs <- asv_table_wide_sample$Sample_ID

asv_table_wide_sample <- asv_table_wide_sample %>%
  ungroup() %>%
  select(-Sample_ID)

## plots the figure
rarecurve(asv_table_wide_sample, step = 20, col = "blue", label = FALSE, 
          main = "Sequencing Effort Curves",
          xlab = "Sequencing Depth", ylab = "Number of ASVs Identified",
          xlim = c(0,1000))
```


summarize in a table how many pcr replicates meet certain read count thresholds 
```{r}
read_summary <- asv_table_filter1 %>%
  filter(!Sample_ID %in% c("34137", "34138", "34139", "34140")) %>%  ## remove wierd yelloweye tissues
  group_by(Sample_ID, sample_type) %>%
  summarize(tot_reads = sum(reads)) %>%
  arrange(desc(tot_reads)) %>%
  group_by(sample_type) %>%
  summarize(atleast1 = sum(tot_reads >= 1),
            atleast100 = sum(tot_reads >= 100),
            atleast200 = sum(tot_reads >= 200),
            atleast500 = sum(tot_reads >= 500),
            atleast1k = sum(tot_reads >= 1000))
```

based on taxa accumulation curve and summary table, we will remove any pcr replicate with fewer than 200 reads from downstream analyses (regardless of sample type)

```{r}
reps_below <- asv_table_filter1 %>%
  group_by(Sample_ID) %>%
  summarise(tot_reads = sum(reads)) %>%
  filter(tot_reads < 200)
```

```{r}
asv_table_filter2 <- asv_table_filter1 %>%
  filter(!Sample_ID %in% reps_below$Sample_ID)
```

```{r}
sum(asv_table_filter1$reads)
sum(asv_table_filter2$reads)
sum(asv_table_long$reads)
```

```{r}
2290034/2295159
```
```{r}
asv_table_with_sample_type %>%
  group_by(sample_type) %>%
  summarize(count = n())
```

```{r}
write.csv(asv_table_filter2, "/home/kimberly.ledger/rockfish_mb/data/decontaminated_asv_table.csv")
```